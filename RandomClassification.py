import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer as TF
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, chi2
from sklearn import metrics
import os, sys, glob
from random import randint
import logging
from time import time
from sklearn.externals import joblib

from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, make_scorer


#logging level
logging.basicConfig(level=logging.INFO)
Logger = logging.getLogger('RandomClf.stdout')
Logger.setLevel("INFO")

def MyTokenizer(Str):
    return Str.split()

def RandomClassification(TestSize, NumFeaturesToBeSelected, FeatureOption):
    '''
    Train a classifier for classifying malwares and goodwares using Random Forest technique
    Compute the prediction accuracy and f1 score of the classifier

    :param String MalwareCorpus: absolute path of the malware corpus
    :param String GoodwareCorpus: absolute path of the goodware corpus
    :param Float TestSize: test set split (default is 0.3 for testing and 0.7 for training)
    :param integer NumFeaturesToBeSelected: number of top features to select
    :param Boolean FeatureOption: False
    '''

    # Step 1: Getting the malware and goodware txt files
    Logger.debug ("Loading Classes samples")
    LotoorSamples = glob.glob(os.path.join("Lotoor",'*txt'))
    MinimobSamples = glob.glob(os.path.join("Minimob",'*txt'))
    YoumiSamples = glob.glob(os.path.join("Youmi",'*txt'))
    Logger.info ("All Samples loaded")

    # Step 2: Creating feature vector
    FeatureVectorizer = TF(input='filename', lowercase=False, token_pattern=None,
                           tokenizer=MyTokenizer, binary=FeatureOption, dtype=np.float64)
    X = FeatureVectorizer.fit_transform(LotoorSamples + MinimobSamples + YoumiSamples)

    # Label malware as 1 and goodware as -1
    LotoorLabels = np.ones(len(LotoorSamples))
    MinimobLabels = np.empty(len(MinimobSamples))
    MinimobLabels.fill(-1)
    YoumiLabels = np.empty(len(YoumiSamples))
    YoumiLabels.fill(0)

    Y = np.concatenate((LotoorLabels, MinimobLabels, YoumiLabels), axis=0)
    Logger.info("Label array - generated")

    # Step 3: Split all samples into training and test set
    XTrain, XTest, YTrain, YTest = train_test_split(X, Y,
                                                        test_size=TestSize, random_state=randint(0,100))
    Logger.debug ("Test set split = %s", TestSize)

    Features = FeatureVectorizer.get_feature_names()
    Logger.info ("Total number of features: {} ".format(len(Features)))

    FSAlgo = None
    if len(Features) > NumFeaturesToBeSelected:
        #with feature selection
        Logger.info ("Gonna select %s features", NumFeaturesToBeSelected)
        FSAlgo = SelectKBest(chi2, k = NumFeaturesToBeSelected)

        XTrain = FSAlgo.fit_transform(XTrain, YTrain)
        XTest = FSAlgo.transform(XTest)
        

    Logger.info ("Gonna perform classification with C-RandomForest")


    # Step 4: model selection through cross validation
    # Assuming RandomForest is the only classifier we are gonna try, we will set the n_estimators parameter as follows.
    Parameters = {'n_estimators': [10,50,100,200,500,1000],
                  'bootstrap': [True, False],
                  'criterion': ['gini', 'entropy']}
    my_scorer = make_scorer(f1_score, greater_is_better=True, average='micro')
    Clf = GridSearchCV(RandomForestClassifier(), Parameters,  cv=5, scoring = my_scorer, n_jobs=-1)
    RFmodels = Clf.fit(XTrain, YTrain)
    
    BestModel = RFmodels.best_estimator_
    filename = 'finalized_model.sav'
    joblib.dump(BestModel, filename)
    filename1 = 'finalized_vector.sav'
    joblib.dump(FeatureVectorizer, filename1)
    filename2 = 'finalized_vector1.sav'
    joblib.dump(FSAlgo, filename2)
    Logger.info('CV done - Best model selected: {}'.format(BestModel))
    
    # Best model is chosen through 5-fold cross validation and stored in the variable: RFmodels

    # Step 5: Evaluate the best model on test set
    
    YPred = RFmodels.predict(XTest)
    Accuracy = precision_score(YTest, YPred, average='micro', labels=[1, -1, 0])
    print "Test Set Accuracy = ", Accuracy
    
    print(metrics.classification_report(YTest, YPred,  labels=[1, -1, 0], target_names=['LotoorLabels', 'MinimobLabels', 'YoumiLabels']))


# python Main.py --randomsplit 1